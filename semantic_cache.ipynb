{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different kinds of Caching to reduce latency of GenAI Application\n",
    "\n",
    "There is [KV-Caching](https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/unleashing-ptu-token-throughput-with-kv-cache-friendly-prompt-on/ba-p/4170161), [Semantic Caching with APIM](https://learn.microsoft.com/en-us/azure/api-management/azure-openai-enable-semantic-caching) and [Semantic Caching with Redis](https://github.com/MicrosoftDocs/azure-docs/blob/main/articles/azure-cache-for-redis/cache-tutorial-semantic-cache.md)\n",
    "\n",
    "\n",
    "This notebook is explore Semantic Caching with Redis\n",
    "\n",
    "**References:**\n",
    "1. https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/tree/main\n",
    "2. https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/blob/main/notebooks-with-techniques/semantic-caching/semantic-caching.ipynb\n",
    "3. https://github.com/MicrosoftDocs/azure-docs/blob/main/articles/azure-cache-for-redis/cache-tutorial-semantic-cache.md\n",
    "4. https://github.com/MicrosoftDocs/azure-docs/blob/main/articles/azure-cache-for-redis/quickstart-create-redis-enterprise.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%pip install openai langchain redis tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -U langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure LLM Models\n",
    "\n",
    "- Import libraries\n",
    "- Configure access information and paths\n",
    "- Configure model parameters\n",
    "- Set Redis connection\n",
    "- Configure Azure Cache for Redis to be used as a semantic cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import redis\n",
    "import os\n",
    "import langchain\n",
    "\n",
    "\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import RedisSemanticCache\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "AZURE_ENDPOINT=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "API_KEY=os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "API_VERSION=os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "LLM_MODEL_NAME=\"gpt-4o\"\n",
    "\n",
    "EMBEDDINGS_MODEL_NAME='text-embedding-ada-002'\n",
    "\n",
    "REDIS_ENDPOINT=os.getenv(\"REDIS_ENDPOINT\")\n",
    "REDIS_PASSWORD=os.getenv(\"REDIS_PASSWORD\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_VERSION\"] = API_VERSION\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = AZURE_ENDPOINT\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=LLM_MODEL_NAME,\n",
    "    model_name=\"gpt-4o\",\n",
    "    openai_api_key=API_KEY,\n",
    "    azure_endpoint=AZURE_ENDPOINT,\n",
    "    openai_api_version=API_VERSION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    model=EMBEDDINGS_MODEL_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example assumes TLS is enabled. If not, use \"redis://\" instead of \"rediss://\n",
    "redis_url = \"rediss://:\" + REDIS_PASSWORD + \"@\"+ REDIS_ENDPOINT\n",
    "\n",
    "# set up the semantic cache for your llm\n",
    "set_llm_cache(RedisSemanticCache(redis_url = redis_url, embedding=embeddings, score_threshold=0.05))\n",
    "\n",
    "#note: you can use score_threshold to change how sensitive the semantic cache is. The lower the score, the less likely it is to use a cached result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the LLM\n",
    "Try runnning again with different queries to see what is cached and what is not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First request (not cached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:1: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "c:\\Users\\sidneyphoon\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain_community\\vectorstores\\redis\\base.py:1163: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_community.vectorstores.redis.schema import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"In a world of joy where dreams take flight,\\nPuppies prance in morning light.\\nWith eyes so bright and hearts so pure,\\nTheir playful spirits, a delightful cure.\\n\\nTiny paws that pitter-pat,\\nWagging tails that go rat-tat-tat.\\nSoft fur like a gentle cloud,\\nTheir happy barks, both clear and loud.\\n\\nThey chase their shadows, tumble, and play,\\nBringing sunshine to any day.\\nWith every lick and nuzzle sweet,\\nThey make our hearts skip a beat.\\n\\nIn their presence, worries fade,\\nA gift of love they serenade.\\nBoundless energy, endless cheer,\\nInnocence that knows no fear.\\n\\nCurled up snug in cozy beds,\\nDreams of bones and soft grass spreads.\\nA bundle of joy, a furry friend,\\nIn puppy love, there's no pretend.\\n\\nSo here's to puppies, small and grand,\\nWith their magic, life feels planned.\\nA touch of wonder, a dash of glee,\\nIn their eyes, the world we see.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 207, 'prompt_tokens': 14, 'total_tokens': 221, 'completion_tokens_details': None}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_67802d9a6d', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}} id='run-371a68a9-a909-4563-927a-1615853f2b58-0' usage_metadata={'input_tokens': 14, 'output_tokens': 207, 'total_tokens': 221}\n",
      "CPU times: total: 469 ms\n",
      "Wall time: 3.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = llm(\"Write a poem about cute puppies.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second request, exact match (cached)\n",
    "As the second request is cached, it returns in <1s. This was the instruction, where every character was an exact match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"In a world of joy where dreams take flight,\\nPuppies prance in morning light.\\nWith eyes so bright and hearts so pure,\\nTheir playful spirits, a delightful cure.\\n\\nTiny paws that pitter-pat,\\nWagging tails that go rat-tat-tat.\\nSoft fur like a gentle cloud,\\nTheir happy barks, both clear and loud.\\n\\nThey chase their shadows, tumble, and play,\\nBringing sunshine to any day.\\nWith every lick and nuzzle sweet,\\nThey make our hearts skip a beat.\\n\\nIn their presence, worries fade,\\nA gift of love they serenade.\\nBoundless energy, endless cheer,\\nInnocence that knows no fear.\\n\\nCurled up snug in cozy beds,\\nDreams of bones and soft grass spreads.\\nA bundle of joy, a furry friend,\\nIn puppy love, there's no pretend.\\n\\nSo here's to puppies, small and grand,\\nWith their magic, life feels planned.\\nA touch of wonder, a dash of glee,\\nIn their eyes, the world we see.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 207, 'prompt_tokens': 14, 'total_tokens': 221, 'completion_tokens_details': None}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_67802d9a6d', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}} id='run-371a68a9-a909-4563-927a-1615853f2b58-0' usage_metadata={'input_tokens': 14, 'output_tokens': 207, 'total_tokens': 221}\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 945 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = llm(\"Write a poem about cute puppies.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third request, semantically similar match (cached)\n",
    "Cached responses do not have to be the exact same input string- semantically similar questions will also match, saving cost and speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"In a world of bustling days and nights,\\nWhere worries weave their tangled plight,\\nThere exists a joy that's pure and brightâ€”\\nThe charm of dogs, so sweet, so light.\\n\\nWith noses twitching, tails that wag,\\nThrough fields of daisies, they bound and brag.\\nTiny paws that dance in play,\\nChasing butterflies away.\\n\\nTheir eyes, two orbs of gleaming trust,\\nIn every glance, a love robust.\\nEars that perk at every sound,\\nIn their presence, peace is found.\\n\\nThey greet each morning with a cheer,\\nTheir happiness so crystal-clear.\\nA bark, a yip, a playful tug,\\nEach moment shared, a heartfelt hug.\\n\\nIn cozy nooks or sunny spots,\\nThey curl in dreams, in sleep, they plot\\nAdventures grand in lands unknown,\\nYet always find their way back home.\\n\\nTheir fur, a palette soft and warm,\\nIn shades that nature does adorn.\\nFrom snowy white to midnight black,\\nA spectrum on a fluffy track.\\n\\nOh, little dogs, with hearts so full,\\nYou make the world a delightful lull.\\nIn every wag, in every lick,\\nA magic spell, a loving trick.\\n\\nSo here's to dogs, so cute, so small,\\nWho bring us smiles, who give their all.\\nIn their embrace, we find our song,\\nWith little dogs, we all belong.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 272, 'prompt_tokens': 15, 'total_tokens': 287, 'completion_tokens_details': None}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_67802d9a6d', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}} id='run-83c7ba55-28a0-4dfe-bf0c-ed7a404a1013-0' usage_metadata={'input_tokens': 15, 'output_tokens': 272, 'total_tokens': 287}\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 343 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = llm(\"Write a poem about cute little dogs.\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
